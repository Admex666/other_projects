{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import schedule\n",
    "import threading\n",
    "from typing import Dict, List, Optional\n",
    "import re\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Logging beállítása\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SofaScoreScraper:\n",
    "    def __init__(self, headless: bool = True):\n",
    "        self.headless = headless\n",
    "        self.driver = None\n",
    "        self.session = requests.Session()\n",
    "        self.base_headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        }\n",
    "        self.session.headers.update(self.base_headers)\n",
    "        \n",
    "    def setup_selenium(self):\n",
    "        \"\"\"Selenium WebDriver beállítása\"\"\"\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            if self.headless:\n",
    "                chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_options.add_argument(\"--disable-gpu\")\n",
    "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "            chrome_options.add_argument(f\"--user-agent={self.base_headers['User-Agent']}\")\n",
    "            \n",
    "            # Felhő környezethez optimalizált beállítások\n",
    "            chrome_options.add_argument(\"--disable-extensions\")\n",
    "            chrome_options.add_argument(\"--disable-plugins\")\n",
    "            chrome_options.add_argument(\"--disable-images\")\n",
    "            \n",
    "            service = Service(ChromeDriverManager().install())\n",
    "            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "            logger.info(\"Selenium WebDriver successfully initialized\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup Selenium: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def extract_match_id_from_url(self, url: str) -> Optional[str]:\n",
    "        \"\"\"Match ID kinyerése az URL-ből\"\"\"\n",
    "        try:\n",
    "            # SofaScore URL pattern: /match/team1-team2/abc#id:12345,tab:statistics\n",
    "            if '#id:' in url:\n",
    "                match_id = url.split('#id:')[1].split(',')[0]\n",
    "                return match_id\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting match ID: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_with_requests(self, url: str) -> Optional[Dict]:\n",
    "        \"\"\"Próbálkozás requests-tel (gyorsabb, de nem mindig működik)\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'lxml')\n",
    "            return self.parse_statistics(soup)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Requests method failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_with_selenium(self, url: str) -> Optional[Dict]:\n",
    "        \"\"\"Selenium használata dinamikus tartalom betöltéséhez\"\"\"\n",
    "        try:\n",
    "            if not self.driver and not self.setup_selenium():\n",
    "                return None\n",
    "            \n",
    "            self.driver.get(url)\n",
    "            \n",
    "            # Várunk, hogy betöltődjön az oldal\n",
    "            wait = WebDriverWait(self.driver, 20)\n",
    "            \n",
    "            # Több lehetséges selector próbálása\n",
    "            selectors_to_try = [\n",
    "                \".pt_sm.bdr-b_lg.ov_hidden\",\n",
    "                \"[data-testid='statistics']\",\n",
    "                \".statistics\",\n",
    "                \"[class*='statistics']\",\n",
    "                \"[class*='stat']\"\n",
    "            ]\n",
    "            \n",
    "            stats_container = None\n",
    "            for selector in selectors_to_try:\n",
    "                try:\n",
    "                    stats_container = wait.until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "                    )\n",
    "                    logger.info(f\"Found stats container with selector: {selector}\")\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if not stats_container:\n",
    "                logger.warning(\"No statistics container found with any selector\")\n",
    "                # Próbáljuk meg a teljes oldal parsing-ot\n",
    "                time.sleep(5)  # További várakozás\n",
    "            else:\n",
    "                time.sleep(3)  # Statisztikák betöltődésére várakozás\n",
    "            \n",
    "            # HTML tartalom lekérése és debug info\n",
    "            page_source = self.driver.page_source\n",
    "            \n",
    "            # Debug: megnézzük mi van az oldalon\n",
    "            soup = BeautifulSoup(page_source, 'lxml')\n",
    "            logger.info(f\"Page title: {soup.title.string if soup.title else 'No title'}\")\n",
    "            \n",
    "            # Keresünk bármilyen div-et ami statisztikára utalhat\n",
    "            potential_stats = soup.find_all('div', string=re.compile(r'xG|Expected|Goals|Shots|Possession', re.I))\n",
    "            logger.info(f\"Found {len(potential_stats)} potential stat elements\")\n",
    "            \n",
    "            return self.parse_statistics(soup)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Selenium scraping failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def parse_statistics(self, soup: BeautifulSoup) -> Dict:\n",
    "        \"\"\"Statisztikák kinyerése a HTML-ből - javított verzió több selector-ral\"\"\"\n",
    "        stats = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'team_stats': {},\n",
    "            'xg_data': {},\n",
    "            'raw_stats': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Debug: nézzük meg mi van az oldalon\n",
    "            logger.info(\"Starting to parse statistics...\")\n",
    "            \n",
    "            # Több lehetséges statisztika konténer keresése\n",
    "            container_selectors = [\n",
    "                'div.pt_sm.bdr-b_lg.ov_hidden',\n",
    "                '[data-testid*=\"stat\"]',\n",
    "                '.statistics-container',\n",
    "                '[class*=\"statistics\"]',\n",
    "                '[class*=\"stat-row\"]',\n",
    "                'div[class*=\"flex\"]'  # SofaScore gyakran flexbox-ot használ\n",
    "            ]\n",
    "            \n",
    "            stats_containers = []\n",
    "            for selector in container_selectors:\n",
    "                containers = soup.select(selector)\n",
    "                if containers:\n",
    "                    stats_containers.extend(containers)\n",
    "                    logger.info(f\"Found {len(containers)} containers with selector: {selector}\")\n",
    "            \n",
    "            # Ha nincs specifikus konténer, keresünk az egész oldalon\n",
    "            if not stats_containers:\n",
    "                logger.info(\"No specific containers found, searching entire page...\")\n",
    "                stats_containers = [soup]\n",
    "            \n",
    "            # Statisztikák keresése különböző módszerekkel\n",
    "            for container in stats_containers:\n",
    "                # 1. módszer: Flexbox alapú keresés\n",
    "                self._parse_flexbox_stats(container, stats)\n",
    "                \n",
    "                # 2. módszer: Szöveg alapú keresés\n",
    "                self._parse_text_based_stats(container, stats)\n",
    "                \n",
    "                # 3. módszer: Table-szerű struktúra\n",
    "                self._parse_table_like_stats(container, stats)\n",
    "            \n",
    "            # xG specifikus keresés\n",
    "            self._extract_xg_data(soup, stats)\n",
    "            \n",
    "            # Csapat nevek kinyerése\n",
    "            team_names = self.extract_team_names(soup)\n",
    "            if team_names:\n",
    "                stats['teams'] = team_names\n",
    "            \n",
    "            logger.info(f\"Successfully parsed {len(stats['raw_stats'])} statistics\")\n",
    "            \n",
    "            # Debug: logoljuk az első pár statisztikát\n",
    "            for i, stat in enumerate(stats['raw_stats'][:3]):\n",
    "                logger.info(f\"Stat {i+1}: {stat}\")\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing statistics: {e}\")\n",
    "            return stats\n",
    "    \n",
    "    def _parse_flexbox_stats(self, container, stats):\n",
    "        \"\"\"Flexbox alapú statisztikák parsing\"\"\"\n",
    "        try:\n",
    "            # Keresünk sorokra osztott statisztikákat\n",
    "            rows = container.find_all('div', class_=re.compile(r'.*flex.*|.*row.*'))\n",
    "            \n",
    "            for row in rows:\n",
    "                text_elements = row.find_all(string=True)\n",
    "                text_content = [t.strip() for t in text_elements if t.strip()]\n",
    "                \n",
    "                # Ha 3 elemet találunk: érték1, név, érték2\n",
    "                if len(text_content) >= 3:\n",
    "                    # Keresünk számokat a szövegben\n",
    "                    numbers = [t for t in text_content if re.match(r'^[\\d.,]+%?$', t)]\n",
    "                    stat_names = [t for t in text_content if not re.match(r'^[\\d.,]+%?$', t) and len(t) > 1]\n",
    "                    \n",
    "                    if len(numbers) >= 2 and stat_names:\n",
    "                        stat_name = stat_names[0]\n",
    "                        stats['raw_stats'].append({\n",
    "                            'stat_name': stat_name,\n",
    "                            'home_value': numbers[0],\n",
    "                            'away_value': numbers[-1]\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error in flexbox parsing: {e}\")\n",
    "    \n",
    "    def _parse_text_based_stats(self, container, stats):\n",
    "        \"\"\"Szöveg alapú statisztika keresés\"\"\"\n",
    "        try:\n",
    "            # Keressük az összes szöveget ami statisztikára utalhat\n",
    "            stat_patterns = [\n",
    "                r'(\\d+[\\.,]?\\d*)\\s*(xG|Expected goals?|Goals?|Shots?|Possession|Pass|Corner|Yellow|Red)',\n",
    "                r'(xG|Expected goals?|Goals?|Shots?|Possession|Pass|Corner|Yellow|Red)\\s*(\\d+[\\.,]?\\d*)',\n",
    "                r'(\\d+[\\.,]?\\d*%?)\\s*([A-Za-z\\s]+)\\s*(\\d+[\\.,]?\\d*%?)'\n",
    "            ]\n",
    "            \n",
    "            page_text = container.get_text()\n",
    "            \n",
    "            for pattern in stat_patterns:\n",
    "                matches = re.finditer(pattern, page_text, re.IGNORECASE)\n",
    "                for match in matches:\n",
    "                    groups = match.groups()\n",
    "                    if len(groups) >= 2:\n",
    "                        # Próbáljuk meghatározni melyik a név és melyik az érték\n",
    "                        if groups[1].replace(' ', '').replace('.', '').replace(',', '').isdigit():\n",
    "                            stat_name = groups[0]\n",
    "                            value = groups[1]\n",
    "                        else:\n",
    "                            stat_name = groups[1]\n",
    "                            value = groups[0]\n",
    "                        \n",
    "                        if stat_name and value:\n",
    "                            stats['raw_stats'].append({\n",
    "                                'stat_name': stat_name,\n",
    "                                'home_value': value,\n",
    "                                'away_value': 'N/A'\n",
    "                            })\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error in text-based parsing: {e}\")\n",
    "    \n",
    "    def _parse_table_like_stats(self, container, stats):\n",
    "        \"\"\"Table-szerű struktúrák parsing\"\"\"\n",
    "        try:\n",
    "            # Keresünk tr, td elemeket\n",
    "            rows = container.find_all(['tr', 'div'])\n",
    "            \n",
    "            for row in rows:\n",
    "                cells = row.find_all(['td', 'div', 'span'])\n",
    "                if len(cells) >= 3:\n",
    "                    cell_texts = [cell.get_text(strip=True) for cell in cells]\n",
    "                    \n",
    "                    # Szűrjük ki az üres cellákat\n",
    "                    cell_texts = [text for text in cell_texts if text]\n",
    "                    \n",
    "                    if len(cell_texts) >= 3:\n",
    "                        # Általában: érték1, statisztika_név, érték2\n",
    "                        potential_left = cell_texts[0]\n",
    "                        potential_name = cell_texts[1]\n",
    "                        potential_right = cell_texts[-1]\n",
    "                        \n",
    "                        # Ellenőrizzük hogy van-e számérték\n",
    "                        if (re.match(r'^[\\d.,]+%?$', potential_left) and \n",
    "                            re.match(r'^[\\d.,]+%?$', potential_right) and\n",
    "                            not re.match(r'^[\\d.,]+%?$', potential_name)):\n",
    "                            \n",
    "                            stats['raw_stats'].append({\n",
    "                                'stat_name': potential_name,\n",
    "                                'home_value': potential_left,\n",
    "                                'away_value': potential_right\n",
    "                            })\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error in table-like parsing: {e}\")\n",
    "    \n",
    "    def _extract_xg_data(self, soup, stats):\n",
    "        \"\"\"xG adatok specifikus kinyerése\"\"\"\n",
    "        try:\n",
    "            # xG keresése különböző módokon\n",
    "            xg_patterns = [\n",
    "                r'xG[:\\s]*(\\d+[\\.,]?\\d*)',\n",
    "                r'Expected\\s+goals?[:\\s]*(\\d+[\\.,]?\\d*)',\n",
    "                r'(\\d+[\\.,]?\\d*)\\s*xG'\n",
    "            ]\n",
    "            \n",
    "            page_text = soup.get_text()\n",
    "            \n",
    "            xg_values = []\n",
    "            for pattern in xg_patterns:\n",
    "                matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
    "                xg_values.extend(matches)\n",
    "            \n",
    "            if len(xg_values) >= 2:\n",
    "                stats['xg_data'] = {\n",
    "                    'home_xg': xg_values[0],\n",
    "                    'away_xg': xg_values[1],\n",
    "                    'stat_name': 'xG'\n",
    "                }\n",
    "                logger.info(f\"Found xG data: {stats['xg_data']}\")\n",
    "            elif len(xg_values) == 1:\n",
    "                stats['xg_data'] = {\n",
    "                    'home_xg': xg_values[0],\n",
    "                    'away_xg': 'N/A',\n",
    "                    'stat_name': 'xG'\n",
    "                }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting xG data: {e}\")\n",
    "\n",
    "\n",
    "    def extract_team_names(self, soup: BeautifulSoup) -> Optional[Dict]:\n",
    "        \"\"\"Csapat nevek kinyerése\"\"\"\n",
    "        try:\n",
    "            # Különböző selectorok próbálása\n",
    "            selectors = [\n",
    "                'h1[data-testid=\"match-header-team-name\"]',\n",
    "                '.team-name',\n",
    "                '[class*=\"team\"][class*=\"name\"]',\n",
    "                'h1, h2, h3'  # Fallback\n",
    "            ]\n",
    "            \n",
    "            for selector in selectors:\n",
    "                elements = soup.select(selector)\n",
    "                if len(elements) >= 2:\n",
    "                    return {\n",
    "                        'home_team': elements[0].get_text(strip=True),\n",
    "                        'away_team': elements[1].get_text(strip=True)\n",
    "                    }\n",
    "            \n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting team names: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_match_stats(self, url: str) -> Optional[Dict]:\n",
    "        \"\"\"Fő scraping függvény - először requests, majd Selenium\"\"\"\n",
    "        logger.info(f\"Starting to scrape: {url}\")\n",
    "        \n",
    "        # Először próbálkozás requests-tel\n",
    "        stats = self.scrape_with_requests(url)\n",
    "        \n",
    "        # Ha nem sikerült, Selenium használata\n",
    "        if not stats or len(stats.get('raw_stats', [])) == 0:\n",
    "            logger.info(\"Trying with Selenium...\")\n",
    "            stats = self.scrape_with_selenium(url)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Erőforrások felszabadítása\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchScheduler:\n",
    "    def __init__(self, scraper: SofaScoreScraper):\n",
    "        self.scraper = scraper\n",
    "        self.results = []\n",
    "        self.running = False\n",
    "        self.thread = None\n",
    "        \n",
    "    def add_match(self, url: str, interval_minutes: int = 5):\n",
    "        \"\"\"Mérkőzés hozzáadása az ütemezéshez\"\"\"\n",
    "        def job():\n",
    "            try:\n",
    "                stats = self.scraper.scrape_match_stats(url)\n",
    "                if stats:\n",
    "                    stats['url'] = url\n",
    "                    self.results.append(stats)\n",
    "                    logger.info(f\"Successfully scraped match data. Total results: {len(self.results)}\")\n",
    "                else:\n",
    "                    logger.warning(\"No stats retrieved\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in scheduled job: {e}\")\n",
    "        \n",
    "        schedule.every(interval_minutes).minutes.do(job)\n",
    "        logger.info(f\"Scheduled match scraping every {interval_minutes} minutes for: {url}\")\n",
    "        \n",
    "        # Első futtatás azonnal\n",
    "        job()\n",
    "    \n",
    "    def start_scheduler(self):\n",
    "        \"\"\"Ütemező indítása külön szálon\"\"\"\n",
    "        def run_scheduler():\n",
    "            self.running = True\n",
    "            while self.running:\n",
    "                schedule.run_pending()\n",
    "                time.sleep(1)\n",
    "        \n",
    "        self.thread = threading.Thread(target=run_scheduler, daemon=True)\n",
    "        self.thread.start()\n",
    "        logger.info(\"Scheduler started\")\n",
    "    \n",
    "    def stop_scheduler(self):\n",
    "        \"\"\"Ütemező leállítása\"\"\"\n",
    "        self.running = False\n",
    "        schedule.clear()\n",
    "        logger.info(\"Scheduler stopped\")\n",
    "    \n",
    "    def get_latest_stats(self) -> Optional[Dict]:\n",
    "        \"\"\"Legfrissebb statisztikák lekérése\"\"\"\n",
    "        if self.results:\n",
    "            return self.results[-1]\n",
    "        return None\n",
    "    \n",
    "    def save_results_to_csv(self, filename: str = None):\n",
    "        \"\"\"Eredmények mentése CSV-be\"\"\"\n",
    "        if not self.results:\n",
    "            logger.warning(\"No results to save\")\n",
    "            return\n",
    "        \n",
    "        if not filename:\n",
    "            filename = f\"sofascore_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        \n",
    "        # DataFrame készítése\n",
    "        rows = []\n",
    "        for result in self.results:\n",
    "            base_row = {\n",
    "                'timestamp': result.get('timestamp'),\n",
    "                'url': result.get('url'),\n",
    "                'home_team': result.get('teams', {}).get('home_team', 'Unknown'),\n",
    "                'away_team': result.get('teams', {}).get('away_team', 'Unknown'),\n",
    "                'home_xg': result.get('xg_data', {}).get('home_xg', 'N/A'),\n",
    "                'away_xg': result.get('xg_data', {}).get('away_xg', 'N/A')\n",
    "            }\n",
    "            \n",
    "            # Egyéb statisztikák hozzáadása\n",
    "            for stat in result.get('raw_stats', []):\n",
    "                base_row[f\"home_{stat['stat_name']}\"] = stat['home_value']\n",
    "                base_row[f\"away_{stat['stat_name']}\"] = stat['away_value']\n",
    "            \n",
    "            rows.append(base_row)\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(filename, index=False)\n",
    "        logger.info(f\"Results saved to {filename}\")\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:18:42,563 - INFO - Starting to scrape: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:18:42,650 - WARNING - Requests method failed: 403 Client Error: Forbidden for url: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:18:42,651 - INFO - Trying with Selenium...\n",
      "2025-07-25 18:18:42,652 - INFO - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏈 Testing single match scraping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:18:43,610 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-07-25 18:18:43,700 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-07-25 18:18:43,765 - INFO - Driver [C:\\Users\\Adam\\.wdm\\drivers\\chromedriver\\win64\\138.0.7204.168\\chromedriver-win32/chromedriver.exe] found in cache\n",
      "2025-07-25 18:18:44,824 - INFO - Selenium WebDriver successfully initialized\n",
      "2025-07-25 18:18:46,963 - INFO - Found stats container with selector: .pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:18:50,248 - INFO - Page title: 1. FC Köln vs Leicester City live score, H2H and lineups | Sofascore\n",
      "2025-07-25 18:18:50,256 - INFO - Found 6 potential stat elements\n",
      "2025-07-25 18:18:50,257 - INFO - Starting to parse statistics...\n",
      "2025-07-25 18:18:50,283 - INFO - Found 1 containers with selector: div.pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:18:50,329 - INFO - Found 1 containers with selector: [data-testid*=\"stat\"]\n",
      "2025-07-25 18:18:50,509 - INFO - Found 253 containers with selector: div[class*=\"flex\"]\n",
      "2025-07-25 18:18:50,824 - INFO - Successfully parsed 354 statistics\n",
      "2025-07-25 18:18:50,825 - INFO - Stat 1: {'stat_name': 'Match overview', 'home_value': '48%', 'away_value': '0'}\n",
      "2025-07-25 18:18:50,825 - INFO - Stat 2: {'stat_name': 'Ball possession', 'home_value': '48%', 'away_value': '52%'}\n",
      "2025-07-25 18:18:50,825 - INFO - Stat 3: {'stat_name': 'Corner kicks', 'home_value': '2', 'away_value': '3'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully scraped statistics!\n",
      "📊 Found 354 statistics\n",
      "🏟️ Teams: {'home_team': '1. FC KölnvsLeicester Citylive score, H2H results, standings and prediction', 'away_team': 'Lineups'}\n",
      "\n",
      "📈 Sample statistics:\n",
      "  Match overview: 48% - 0\n",
      "  Ball possession: 48% - 52%\n",
      "  Corner kicks: 2 - 3\n",
      "  Fouls: 9 - 6\n",
      "  Free kicks: 6 - 9\n"
     ]
    }
   ],
   "source": [
    "# Használati példa és tesztelés\n",
    "\n",
    "# Scraper inicializálás\n",
    "scraper = SofaScoreScraper(headless=True)  # headless=False a teszteléshez\n",
    "\n",
    "# Tesztelés egyedi URL-lel\n",
    "test_url = \"https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\"\n",
    "\n",
    "print(\"🏈 Testing single match scraping...\")\n",
    "stats = scraper.scrape_match_stats(test_url)\n",
    "\n",
    "if stats:\n",
    "    print(f\"✅ Successfully scraped statistics!\")\n",
    "    print(f\"📊 Found {len(stats.get('raw_stats', []))} statistics\")\n",
    "    \n",
    "    if stats.get('xg_data'):\n",
    "        print(f\"⚽ xG found: {stats['xg_data']}\")\n",
    "    else:\n",
    "        print(\"❌ No xG data found\")\n",
    "    \n",
    "    xg_stats = [s for s in stats['raw_stats'] if 'xG' in s['stat_name'] or 'Expected' in s['stat_name']]\n",
    "    print(f\"🎯 xG related stats: {xg_stats}\")\n",
    "\n",
    "    if stats.get('teams'):\n",
    "        print(f\"🏟️ Teams: {stats['teams']}\")\n",
    "    \n",
    "    # Első néhány statisztika megjelenítése\n",
    "    print(\"\\n📈 Sample statistics:\")\n",
    "    for stat in stats.get('raw_stats', [])[:5]:\n",
    "        print(f\"  {stat['stat_name']}: {stat['home_value']} - {stat['away_value']}\")\n",
    "else:\n",
    "    print(\"❌ Failed to scrape statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:23:48,875 - INFO - Scheduled match scraping every 1 minutes for: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:23:48,876 - INFO - Starting to scrape: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:23:48,963 - WARNING - Requests method failed: 403 Client Error: Forbidden for url: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:23:48,964 - INFO - Trying with Selenium...\n",
      "2025-07-25 18:23:48,989 - INFO - Found stats container with selector: .pt_sm.bdr-b_lg.ov_hidden\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🕐 Setting up scheduled scraping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:23:52,272 - INFO - Page title: 1. FC Köln vs Leicester City live score, H2H and lineups | Sofascore\n",
      "2025-07-25 18:23:52,280 - INFO - Found 6 potential stat elements\n",
      "2025-07-25 18:23:52,283 - INFO - Starting to parse statistics...\n",
      "2025-07-25 18:23:52,320 - INFO - Found 1 containers with selector: div.pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:23:52,366 - INFO - Found 1 containers with selector: [data-testid*=\"stat\"]\n",
      "2025-07-25 18:23:52,542 - INFO - Found 253 containers with selector: div[class*=\"flex\"]\n",
      "2025-07-25 18:23:52,855 - INFO - Successfully parsed 354 statistics\n",
      "2025-07-25 18:23:52,856 - INFO - Stat 1: {'stat_name': 'Match overview', 'home_value': '48%', 'away_value': '0'}\n",
      "2025-07-25 18:23:52,857 - INFO - Stat 2: {'stat_name': 'Ball possession', 'home_value': '48%', 'away_value': '52%'}\n",
      "2025-07-25 18:23:52,857 - INFO - Stat 3: {'stat_name': 'Corner kicks', 'home_value': '2', 'away_value': '3'}\n",
      "2025-07-25 18:23:52,858 - INFO - Successfully scraped match data. Total results: 1\n",
      "2025-07-25 18:23:52,859 - INFO - Scheduler started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ Scheduler started! It will scrape every 1 minutes.\n",
      "💡 Run the next cell to check results after a few minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:24:48,888 - INFO - Starting to scrape: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:24:48,985 - WARNING - Requests method failed: 403 Client Error: Forbidden for url: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:24:48,985 - INFO - Trying with Selenium...\n",
      "2025-07-25 18:24:49,020 - INFO - Found stats container with selector: .pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:24:52,687 - INFO - Page title: 1. FC Köln vs Leicester City live score, H2H and lineups | Sofascore\n",
      "2025-07-25 18:24:52,696 - INFO - Found 6 potential stat elements\n",
      "2025-07-25 18:24:52,697 - INFO - Starting to parse statistics...\n",
      "2025-07-25 18:24:52,726 - INFO - Found 1 containers with selector: div.pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:24:52,778 - INFO - Found 1 containers with selector: [data-testid*=\"stat\"]\n",
      "2025-07-25 18:24:52,971 - INFO - Found 253 containers with selector: div[class*=\"flex\"]\n",
      "2025-07-25 18:24:53,296 - INFO - Successfully parsed 354 statistics\n",
      "2025-07-25 18:24:53,297 - INFO - Stat 1: {'stat_name': 'Match overview', 'home_value': '49%', 'away_value': '0'}\n",
      "2025-07-25 18:24:53,298 - INFO - Stat 2: {'stat_name': 'Ball possession', 'home_value': '49%', 'away_value': '51%'}\n",
      "2025-07-25 18:24:53,298 - INFO - Stat 3: {'stat_name': 'Corner kicks', 'home_value': '2', 'away_value': '3'}\n",
      "2025-07-25 18:24:53,299 - INFO - Successfully scraped match data. Total results: 2\n",
      "2025-07-25 18:25:54,333 - INFO - Starting to scrape: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:25:54,426 - WARNING - Requests method failed: 403 Client Error: Forbidden for url: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:25:54,427 - INFO - Trying with Selenium...\n",
      "2025-07-25 18:25:54,446 - INFO - Found stats container with selector: .pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:25:58,283 - INFO - Page title: 1. FC Köln vs Leicester City live score, H2H and lineups | Sofascore\n",
      "2025-07-25 18:25:58,291 - INFO - Found 6 potential stat elements\n",
      "2025-07-25 18:25:58,291 - INFO - Starting to parse statistics...\n",
      "2025-07-25 18:25:58,320 - INFO - Found 1 containers with selector: div.pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:25:58,369 - INFO - Found 1 containers with selector: [data-testid*=\"stat\"]\n",
      "2025-07-25 18:25:58,554 - INFO - Found 263 containers with selector: div[class*=\"flex\"]\n",
      "2025-07-25 18:25:58,881 - INFO - Successfully parsed 354 statistics\n",
      "2025-07-25 18:25:58,881 - INFO - Stat 1: {'stat_name': 'Match overview', 'home_value': '49%', 'away_value': '0'}\n",
      "2025-07-25 18:25:58,882 - INFO - Stat 2: {'stat_name': 'Ball possession', 'home_value': '49%', 'away_value': '51%'}\n",
      "2025-07-25 18:25:58,882 - INFO - Stat 3: {'stat_name': 'Corner kicks', 'home_value': '2', 'away_value': '4'}\n",
      "2025-07-25 18:25:58,883 - INFO - Successfully scraped match data. Total results: 5\n",
      "2025-07-25 18:26:48,915 - INFO - Starting to scrape: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:26:48,997 - WARNING - Requests method failed: 403 Client Error: Forbidden for url: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:26:48,998 - INFO - Trying with Selenium...\n",
      "2025-07-25 18:26:49,018 - INFO - Found stats container with selector: .pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:26:52,331 - INFO - Page title: 1. FC Köln vs Leicester City live score, H2H and lineups | Sofascore\n",
      "2025-07-25 18:26:52,339 - INFO - Found 6 potential stat elements\n",
      "2025-07-25 18:26:52,340 - INFO - Starting to parse statistics...\n",
      "2025-07-25 18:26:52,367 - INFO - Found 1 containers with selector: div.pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:26:52,418 - INFO - Found 1 containers with selector: [data-testid*=\"stat\"]\n",
      "2025-07-25 18:26:52,619 - INFO - Found 263 containers with selector: div[class*=\"flex\"]\n",
      "2025-07-25 18:26:52,945 - INFO - Successfully parsed 354 statistics\n",
      "2025-07-25 18:26:52,946 - INFO - Stat 1: {'stat_name': 'Match overview', 'home_value': '49%', 'away_value': '0'}\n",
      "2025-07-25 18:26:52,946 - INFO - Stat 2: {'stat_name': 'Ball possession', 'home_value': '49%', 'away_value': '51%'}\n",
      "2025-07-25 18:26:52,947 - INFO - Stat 3: {'stat_name': 'Corner kicks', 'home_value': '2', 'away_value': '4'}\n",
      "2025-07-25 18:26:52,948 - INFO - Successfully scraped match data. Total results: 2\n",
      "2025-07-25 18:26:58,952 - INFO - Starting to scrape: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:26:59,060 - WARNING - Requests method failed: 403 Client Error: Forbidden for url: https://www.sofascore.com/football/match/1-fc-koln-leicester-city/Gswdb#id:14250691,tab:statistics\n",
      "2025-07-25 18:26:59,060 - INFO - Trying with Selenium...\n",
      "2025-07-25 18:26:59,081 - INFO - Found stats container with selector: .pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:27:02,361 - INFO - Page title: 1. FC Köln vs Leicester City live score, H2H and lineups | Sofascore\n",
      "2025-07-25 18:27:02,369 - INFO - Found 6 potential stat elements\n",
      "2025-07-25 18:27:02,369 - INFO - Starting to parse statistics...\n",
      "2025-07-25 18:27:02,397 - INFO - Found 1 containers with selector: div.pt_sm.bdr-b_lg.ov_hidden\n",
      "2025-07-25 18:27:02,444 - INFO - Found 1 containers with selector: [data-testid*=\"stat\"]\n",
      "2025-07-25 18:27:02,627 - INFO - Found 263 containers with selector: div[class*=\"flex\"]\n",
      "2025-07-25 18:27:02,951 - INFO - Successfully parsed 354 statistics\n",
      "2025-07-25 18:27:02,952 - INFO - Stat 1: {'stat_name': 'Match overview', 'home_value': '49%', 'away_value': '0'}\n",
      "2025-07-25 18:27:02,952 - INFO - Stat 2: {'stat_name': 'Ball possession', 'home_value': '49%', 'away_value': '51%'}\n",
      "2025-07-25 18:27:02,953 - INFO - Stat 3: {'stat_name': 'Corner kicks', 'home_value': '2', 'away_value': '4'}\n",
      "2025-07-25 18:27:02,953 - INFO - Successfully scraped match data. Total results: 6\n"
     ]
    }
   ],
   "source": [
    "# Ütemezett scraping példa\n",
    "\n",
    "print(\"\\n🕐 Setting up scheduled scraping...\")\n",
    "scheduler = MatchScheduler(scraper)\n",
    "\n",
    "# Mérkőzés hozzáadása 2 perces intervallumal (teszteléshez)\n",
    "scheduler.add_match(test_url, interval_minutes=1)\n",
    "\n",
    "# Ütemező indítása\n",
    "scheduler.start_scheduler()\n",
    "\n",
    "print(\"⏰ Scheduler started! It will scrape every 1 minutes.\")\n",
    "print(\"💡 Run the next cell to check results after a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:25:10,616 - INFO - Results saved to sofascore_stats_20250725_182510.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Current results:\n",
      "Total scraping results: 3\n",
      "\n",
      "🕐 Latest timestamp: 2025-07-25T18:24:53.347017\n",
      "💾 Results saved to: sofascore_stats_20250725_182510.csv\n",
      "\n",
      "📋 Sample results:\n",
      "               Time Home xG Away xG  Stats Count\n",
      "2025-07-25T18:23:52     N/A     N/A          354\n",
      "2025-07-25T18:24:52     N/A     N/A          354\n",
      "2025-07-25T18:24:53     N/A     N/A          354\n"
     ]
    }
   ],
   "source": [
    "# Eredmények ellenőrzése és mentése\n",
    "\n",
    "print(\"📊 Current results:\")\n",
    "print(f\"Total scraping results: {len(scheduler.results)}\")\n",
    "\n",
    "if scheduler.results:\n",
    "    latest = scheduler.get_latest_stats()\n",
    "    if latest:\n",
    "        print(f\"\\n🕐 Latest timestamp: {latest.get('timestamp')}\")\n",
    "        if latest.get('xg_data'):\n",
    "            print(f\"⚽ Latest xG: {latest['xg_data']}\")\n",
    "    \n",
    "    # CSV mentés\n",
    "    csv_file = scheduler.save_results_to_csv()\n",
    "    print(f\"💾 Results saved to: {csv_file}\")\n",
    "    \n",
    "    # Egyszerű DataFrame megjelenítés\n",
    "    if len(scheduler.results) > 0:\n",
    "        sample_data = []\n",
    "        for result in scheduler.results[-3:]:  # Utolsó 3 eredmény\n",
    "            sample_data.append({\n",
    "                'Time': result.get('timestamp', '')[:19],  # Dátum/idő rövidítve\n",
    "                'Home xG': result.get('xg_data', {}).get('home_xg', 'N/A'),\n",
    "                'Away xG': result.get('xg_data', {}).get('away_xg', 'N/A'),\n",
    "                'Stats Count': len(result.get('raw_stats', []))\n",
    "            })\n",
    "        \n",
    "        df_sample = pd.DataFrame(sample_data)\n",
    "        print(\"\\n📋 Sample results:\")\n",
    "        print(df_sample.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Deployment options printed above!\n"
     ]
    }
   ],
   "source": [
    "# Felhő deployment segédkód\n",
    "\n",
    "\"\"\"\n",
    "🌐 FELHŐ DEPLOYMENT OPCIÓK:\n",
    "\n",
    "1. GOOGLE COLAB:\n",
    "   - Ingyenes GPU/TPU access\n",
    "   - Jupyter notebook környezet\n",
    "   - Korlátozott futási idő (12-24 óra)\n",
    "\n",
    "2. KAGGLE KERNELS:\n",
    "   - Heti 30 óra GPU idő\n",
    "   - Internet access korlátozott\n",
    "   - Notebook környezet\n",
    "\n",
    "3. GITHUB ACTIONS (Ingyenes tier):\n",
    "   - Cron job alapú ütemezés\n",
    "   - 2000 perc/hó limit\n",
    "   - Eredmények GitHub-ra mentése\n",
    "\n",
    "4. RAILWAY/RENDER (Ingyenes tier):\n",
    "   - 24/7 futás\n",
    "   - Kis resource limit\n",
    "   - Web app formában\n",
    "\n",
    "GitHub Actions workflow példa (.github/workflows/scraper.yml):\n",
    "\n",
    "name: SofaScore Scraper\n",
    "on:\n",
    "  schedule:\n",
    "    - cron: '*/30 * * * *'  # 30 percenként\n",
    "  workflow_dispatch:\n",
    "\n",
    "jobs:\n",
    "  scrape:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "    - name: Set up Python\n",
    "      uses: actions/setup-python@v2\n",
    "      with:\n",
    "        python-version: 3.9\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        pip install requests beautifulsoup4 selenium pandas\n",
    "        sudo apt-get update\n",
    "        sudo apt-get install -y chromium-browser\n",
    "    - name: Run scraper\n",
    "      run: python scraper.py\n",
    "    - name: Commit results\n",
    "      run: |\n",
    "        git config --local user.email \"action@github.com\"\n",
    "        git config --local user.name \"GitHub Action\"\n",
    "        git add *.csv\n",
    "        git commit -m \"Update scraping results\" || exit 0\n",
    "        git push\n",
    "\"\"\"\n",
    "\n",
    "print(\"🚀 Deployment options printed above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 18:27:13,484 - INFO - Scheduler stopped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Cleaning up...\n",
      "✅ Cleanup completed!\n"
     ]
    }
   ],
   "source": [
    "# Cleanup és leállítás\n",
    "\n",
    "print(\"🧹 Cleaning up...\")\n",
    "scheduler.stop_scheduler()\n",
    "scraper.cleanup()\n",
    "print(\"✅ Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 📝 Használati útmutató\n",
    "# \n",
    "# ### Alapvető használat:\n",
    "# 1. Futtasd le a csomagtelepítést és importokat\n",
    "# 2. Állítsd be a `test_url` változót a kívánt SofaScore mérkőzés URL-jével\n",
    "# 3. Futtasd le a tesztelő cellát\n",
    "# 4. Indítsd el az ütemezett scrapinget\n",
    "# \n",
    "# ### Testreszabási lehetőségek:\n",
    "# - `interval_minutes`: Scraping gyakoriság módosítása\n",
    "# - `headless`: False értékkel látható böngésző ablak\n",
    "# - `save_results_to_csv()`: Automatikus mentés beállítása\n",
    "# \n",
    "# ### Hibaelhárítás:\n",
    "# - Ha nem működik a requests módszer, a Selenium automatikusan átveszi\n",
    "# - Chrome driver automatikusan települ a webdriver-manager segítségével\n",
    "# - Részletes logok a hibák nyomon követéséhez\n",
    "# \n",
    "# ### Teljesítmény optimalizálás:\n",
    "# - Headless mód gyorsabb futáshoz\n",
    "# - Requests először próbálkozik (gyorsabb)\n",
    "# - Selenium csak szükség esetén (megbízhatóbb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
